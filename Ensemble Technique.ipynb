{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3042364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7a2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.535620</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.253102</td>\n",
       "      <td>0.502439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.377309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.325062</td>\n",
       "      <td>0.563415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.522427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.250620</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.617073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.330025</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location   MinTemp  Rainfall  WindGustDir  WindGustSpeed  WindDir9am  \\\n",
       "0  0.041667  0.535620  0.021898     0.866667       0.527778    0.866667   \n",
       "1  0.041667  0.377309  0.000000     0.933333       0.527778    0.400000   \n",
       "2  0.041667  0.522427  0.000000     1.000000       0.555556    0.866667   \n",
       "3  0.041667  0.424802  0.000000     0.266667       0.250000    0.600000   \n",
       "4  0.041667  0.643799  0.036496     0.866667       0.486111    0.066667   \n",
       "\n",
       "   WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
       "0    0.933333      0.512821      0.545455     0.666667     0.212121   \n",
       "1    1.000000      0.102564      0.500000     0.356322     0.242424   \n",
       "2    1.000000      0.487179      0.590909     0.287356     0.292929   \n",
       "3    0.000000      0.282051      0.204545     0.367816     0.151515   \n",
       "4    0.466667      0.179487      0.454545     0.793103     0.323232   \n",
       "\n",
       "   Pressure9am   Temp3pm  RainToday  RainTomorrow  Season  \n",
       "0     0.253102  0.502439          0             0     0.4  \n",
       "1     0.325062  0.563415          0             0     0.4  \n",
       "2     0.250620  0.536585          0             0     0.4  \n",
       "3     0.498759  0.617073          0             0     0.4  \n",
       "4     0.330025  0.695122          0             0     0.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the claims data\n",
    "\n",
    "data=pd.read_csv(r\"final_data.csv\",header=0)\n",
    "data_bk=data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b577b5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location', 'MinTemp', 'Rainfall', 'WindGustDir', 'WindGustSpeed',\n",
       "       'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
       "       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Temp3pm', 'RainToday',\n",
       "       'RainTomorrow', 'Season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0056c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indepvar=[]\n",
    "for col in data.columns:\n",
    "    if col!='RainTomorrow':\n",
    "        indepvar.append(col)\n",
    "depvar='RainTomorrow'\n",
    "x=data[indepvar]\n",
    "y=data[depvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f550bc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96930, 15), (41542, 15), (96930,), (41542,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d151c35",
   "metadata": {},
   "source": [
    "VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41534b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Metrics (Weighted):\n",
      "              Metric     Value\n",
      "0           Accuracy  0.860310\n",
      "1          Precision  0.731190\n",
      "2             Recall  0.491628\n",
      "3           F1 Score  0.587943\n",
      "4  Balanced Accuracy  0.722838\n",
      "5  Matthews Corrcoef  0.522205\n",
      "6            ROC AUC  0.876369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Create base models\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "xgboost_model = xgb.XGBClassifier(verbosity=0)\n",
    "\n",
    "\n",
    "# Create a VotingClassifier with weights\n",
    "ensemble_model_weighted = VotingClassifier(estimators=[('catboost', catboost_model), ('xgboost', xgboost_model)],\n",
    "                                           voting='soft', weights=[2, 1])\n",
    "\n",
    "\n",
    "# Train the ensemble model with weights\n",
    "ensemble_model_weighted.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the ensemble model with weights\n",
    "y_pred_weighted = ensemble_model_weighted.predict(x_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "precision_weighted = precision_score(y_test, y_pred_weighted)\n",
    "recall_weighted = recall_score(y_test, y_pred_weighted)\n",
    "f1_weighted = f1_score(y_test, y_pred_weighted)\n",
    "balanced_accuracy_weighted = balanced_accuracy_score(y_test, y_pred_weighted)\n",
    "matthews_corr_weighted = matthews_corrcoef(y_test, y_pred_weighted)\n",
    "roc_auc_weighted = roc_auc_score(y_test, ensemble_model_weighted.predict_proba(x_test)[:, 1])\n",
    "\n",
    "# Create a DataFrame with the metrics\n",
    "results_df_weighted = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Balanced Accuracy', 'Matthews Corrcoef', 'ROC AUC'],\n",
    "    'Value': [accuracy_weighted, precision_weighted, recall_weighted, f1_weighted, balanced_accuracy_weighted,\n",
    "              matthews_corr_weighted, roc_auc_weighted]\n",
    "})\n",
    "\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Ensemble Model Metrics (Weighted):\")\n",
    "print(results_df_weighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0330d278",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781c1e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Metric                                            Value\n",
      "0           Accuracy                                         0.860262\n",
      "1          Precision                                         0.724434\n",
      "2             Recall                                         0.501366\n",
      "3           F1 Score                                         0.592603\n",
      "4  Balanced Accuracy                                         0.726438\n",
      "5  Matthews Corrcoef                                         0.524245\n",
      "6            ROC AUC                                         0.877553\n",
      "7    Best Parameters  {'catboost__depth': 8, 'xgboost__max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Assuming df_resampled is your DataFrame\n",
    "# Split the data into features (X) and target variable (y)\n",
    "\n",
    "# Create base models\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "xgboost_model = XGBClassifier(verbosity=0)\n",
    "\n",
    "# Create a VotingClassifier with weights\n",
    "ensemble_model_weighted = VotingClassifier(estimators=[('catboost', catboost_model), ('xgboost', xgboost_model)],\n",
    "                                           voting='soft', weights=[2, 1])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'catboost__depth': [4, 6, 8],\n",
    "    'xgboost__max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(ensemble_model_weighted, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "matthews_corr = matthews_corrcoef(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, best_model.predict_proba(x_test)[:, 1])\n",
    "\n",
    "# Create a DataFrame with the metrics and best parameters\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Balanced Accuracy', 'Matthews Corrcoef', 'ROC AUC'],\n",
    "    'Value': [accuracy, precision, recall, f1, balanced_accuracy, matthews_corr, roc_auc]\n",
    "})\n",
    "\n",
    "# Add the best parameters to the DataFrame\n",
    "results_df.loc[len(results_df)] = ['Best Parameters', grid_search.best_params_]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('hypertuning_metrics.csv', index=False)\n",
    "\n",
    "# Print the metrics and best parameters\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b58f3",
   "metadata": {},
   "source": [
    "KFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6bafb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 5\n",
      "Fold 1: Accuracy = 0.8602996930853944\n",
      "Fold 2: Accuracy = 0.860588553890594\n",
      "Fold 3: Accuracy = 0.8614862425074024\n",
      "Fold 4: Accuracy = 0.8601141041380804\n",
      "Fold 5: Accuracy = 0.8613779157940348\n",
      "Mean Metrics for All Folds:\n",
      "accuracy: 0.8607733018831011\n",
      "precision: 0.7375129754487006\n",
      "recall: 0.49936797647832476\n",
      "f1: 0.5955004772990329\n",
      "roc_auc: 0.8783341638922428\n",
      "k_value: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maha\\AppData\\Local\\Temp\\ipykernel_19976\\1928167893.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Assuming df_resampled is your DataFrame\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "# Modify the main loop to use the best model with specified hyperparameters and cross-validation\n",
    "def cross_validation_with_best_model(X, y, num_folds, best_model):\n",
    "    all_fold_metrics = []\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        fold_metrics = {}\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        fold_metrics['precision'] = precision_score(y_test, y_pred)\n",
    "        fold_metrics['recall'] = recall_score(y_test, y_pred)\n",
    "        fold_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "        fold_metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
    "   \n",
    "        all_fold_metrics.append(fold_metrics)\n",
    "\n",
    "        print(f'Fold {fold_num + 1}: Accuracy = {fold_metrics[\"accuracy\"]}')\n",
    "\n",
    "    return all_fold_metrics\n",
    "\n",
    "# Define k-fold cross-validation settings\n",
    "kf_5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "kf_15 = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "kf_20 = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through different numbers of folds\n",
    "kfolds = [kf_5]# kf_10, kf_15, kf_20\n",
    "\n",
    "# Create an empty DataFrame to store mean metrics\n",
    "mean_metrics_df = pd.DataFrame()\n",
    "\n",
    "for num_folds, kf in zip([5, 10, 15, 20], kfolds):\n",
    "    print(f'Number of Folds: {num_folds}')\n",
    "\n",
    "    # Perform cross-validation for each fold\n",
    "    fold_metrics = cross_validation_with_best_model(X, y, num_folds, best_model)\n",
    "\n",
    "    # Calculate and print mean of metrics for all folds\n",
    "    mean_metrics = {metric: np.mean([fold[metric] for fold in fold_metrics]) for metric in fold_metrics[0]}\n",
    "    mean_metrics['k_value'] = num_folds\n",
    "    # Append mean metrics to the DataFrame\n",
    "    mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n",
    "\n",
    "    # Print mean metrics for all folds\n",
    "    print('Mean Metrics for All Folds:')\n",
    "    for metric, value in mean_metrics.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20c212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 10\n",
      "Fold 1: Accuracy = 0.8586799537839399\n",
      "Fold 2: Accuracy = 0.8611351819757366\n",
      "Fold 3: Accuracy = 0.8623528562143424\n",
      "Fold 4: Accuracy = 0.8597530150935221\n",
      "Fold 5: Accuracy = 0.8617028959341374\n",
      "Fold 6: Accuracy = 0.8620639849786957\n",
      "Fold 7: Accuracy = 0.8580197876796418\n",
      "Fold 8: Accuracy = 0.8635083411569293\n",
      "Fold 9: Accuracy = 0.8565032136924966\n",
      "Fold 10: Accuracy = 0.8661804000866614\n",
      "Mean Metrics for All Folds:\n",
      "accuracy: 0.8609899630596104\n",
      "precision: 0.7372954574477745\n",
      "recall: 0.5013215202750827\n",
      "f1: 0.5967640021287994\n",
      "roc_auc: 0.8795187462199967\n",
      "k_value: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maha\\AppData\\Local\\Temp\\ipykernel_19976\\2446411022.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    " \n",
    ")\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "\n",
    "# Modify the main loop to use LightGBM with specified hyperparameters and cross-validation\n",
    "def voting_cross_validation(X, y, num_folds):\n",
    "    all_fold_metrics = []\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        fold_metrics = {}\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        fold_metrics['precision'] = precision_score(y_test, y_pred)\n",
    "        fold_metrics['recall'] = recall_score(y_test, y_pred)\n",
    "        fold_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "       \n",
    "        fold_metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
    "       \n",
    "\n",
    "        all_fold_metrics.append(fold_metrics)\n",
    "\n",
    "        print(f'Fold {fold_num + 1}: Accuracy = {fold_metrics[\"accuracy\"]}')\n",
    "\n",
    "    return all_fold_metrics\n",
    "\n",
    "# Define k-fold cross-validation settings\n",
    "kf_5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "kf_15 = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "kf_20 = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through different numbers of folds\n",
    "kfolds = [kf_10]# kf_10, kf_15, kf_20\n",
    "\n",
    "\n",
    "for num_folds, kf in zip([10], kfolds):\n",
    "    print(f'Number of Folds: {num_folds}')\n",
    "\n",
    "    # Perform cross-validation for each fold\n",
    "    fold_metrics = voting_cross_validation(X, y, num_folds)\n",
    "\n",
    "    # Calculate and print mean of metrics for all folds\n",
    "    mean_metrics = {metric: np.mean([fold[metric] for fold in fold_metrics]) for metric in fold_metrics[0]}\n",
    "    mean_metrics['k_value'] = num_folds\n",
    "    # Append mean metrics to the DataFrame\n",
    "    mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n",
    "\n",
    "    # Print mean metrics for all folds\n",
    "    print('Mean Metrics for All Folds:')\n",
    "    for metric, value in mean_metrics.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "# Save mean metrics to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd3bbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 15\n",
      "Fold 1: Accuracy = 0.8611351819757366\n",
      "Fold 2: Accuracy = 0.8596187175043327\n",
      "Fold 3: Accuracy = 0.8623266897746967\n",
      "Fold 4: Accuracy = 0.8642764298093587\n",
      "Fold 5: Accuracy = 0.8636265164644714\n",
      "Fold 6: Accuracy = 0.8623266897746967\n",
      "Fold 7: Accuracy = 0.8636265164644714\n",
      "Fold 8: Accuracy = 0.8590618567869137\n",
      "Fold 9: Accuracy = 0.8656700249160437\n",
      "Fold 10: Accuracy = 0.8593868486621168\n",
      "Fold 11: Accuracy = 0.8615534611634709\n",
      "Fold 12: Accuracy = 0.8613367999133354\n",
      "Fold 13: Accuracy = 0.8584118730365075\n",
      "Fold 14: Accuracy = 0.8598201711623876\n",
      "Fold 15: Accuracy = 0.8643700574152313\n",
      "Mean Metrics for All Folds:\n",
      "accuracy: 0.8617698556549181\n",
      "precision: 0.7408367323682826\n",
      "recall: 0.501898065683125\n",
      "f1: 0.5983397918454697\n",
      "roc_auc: 0.8798074135442577\n",
      "k_value: 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maha\\AppData\\Local\\Temp\\ipykernel_19976\\4011020265.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "\n",
    "# Modify the main loop to use LightGBM with specified hyperparameters and cross-validation\n",
    "def voting_cross_validation(X, y, num_folds):\n",
    "    all_fold_metrics = []\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        fold_metrics = {}\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        fold_metrics['precision'] = precision_score(y_test, y_pred)\n",
    "        fold_metrics['recall'] = recall_score(y_test, y_pred)\n",
    "        fold_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "        fold_metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
    "       \n",
    "\n",
    "        all_fold_metrics.append(fold_metrics)\n",
    "\n",
    "        print(f'Fold {fold_num + 1}: Accuracy = {fold_metrics[\"accuracy\"]}')\n",
    "\n",
    "    return all_fold_metrics\n",
    "\n",
    "# Define k-fold cross-validation settings\n",
    "kf_5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "kf_15 = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "kf_20 = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through different numbers of folds\n",
    "kfolds = [kf_15]# kf_10, kf_15, kf_20\n",
    "\n",
    "\n",
    "for num_folds, kf in zip([15], kfolds):\n",
    "    print(f'Number of Folds: {num_folds}')\n",
    "\n",
    "    # Perform cross-validation for each fold\n",
    "    fold_metrics = voting_cross_validation(X, y, num_folds)\n",
    "\n",
    "    # Calculate and print mean of metrics for all folds\n",
    "    mean_metrics = {metric: np.mean([fold[metric] for fold in fold_metrics]) for metric in fold_metrics[0]}\n",
    "    mean_metrics['k_value'] = num_folds\n",
    "    # Append mean metrics to the DataFrame\n",
    "    mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n",
    "\n",
    "    # Print mean metrics for all folds\n",
    "    print('Mean Metrics for All Folds:')\n",
    "    for metric, value in mean_metrics.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "# Save mean metrics to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d22b7532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds: 20\n",
      "Fold 1: Accuracy = 0.8610629693818602\n",
      "Fold 2: Accuracy = 0.8591854419410745\n",
      "Fold 3: Accuracy = 0.857163489312536\n",
      "Fold 4: Accuracy = 0.8653957250144425\n",
      "Fold 5: Accuracy = 0.8658290005777007\n",
      "Fold 6: Accuracy = 0.8587521663778163\n",
      "Fold 7: Accuracy = 0.858318890814558\n",
      "Fold 8: Accuracy = 0.8578856152512998\n",
      "Fold 9: Accuracy = 0.8612073945696129\n",
      "Fold 10: Accuracy = 0.8588965915655691\n",
      "Fold 11: Accuracy = 0.8603408434430965\n",
      "Fold 12: Accuracy = 0.8642403235124205\n",
      "Fold 13: Accuracy = 0.8593095478838654\n",
      "Fold 14: Accuracy = 0.8574317492416582\n",
      "Fold 15: Accuracy = 0.8665318503538928\n",
      "Fold 16: Accuracy = 0.8614762386248737\n",
      "Fold 17: Accuracy = 0.8575761952910588\n",
      "Fold 18: Accuracy = 0.8575761952910588\n",
      "Fold 19: Accuracy = 0.8646540517116856\n",
      "Fold 20: Accuracy = 0.8691318792431028\n",
      "Mean Metrics for All Folds:\n",
      "accuracy: 0.8610983079701592\n",
      "precision: 0.73776087706573\n",
      "recall: 0.5011692879722266\n",
      "f1: 0.5967745722906659\n",
      "roc_auc: 0.8795928385280425\n",
      "k_value: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maha\\AppData\\Local\\Temp\\ipykernel_19976\\3703833889.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "\n",
    "# Modify the main loop to use LightGBM with specified hyperparameters and cross-validation\n",
    "def voting_cross_validation(X, y, num_folds):\n",
    "    all_fold_metrics = []\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        fold_metrics = {}\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        fold_metrics['precision'] = precision_score(y_test, y_pred)\n",
    "        fold_metrics['recall'] = recall_score(y_test, y_pred)\n",
    "        fold_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "        fold_metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "        all_fold_metrics.append(fold_metrics)\n",
    "\n",
    "        print(f'Fold {fold_num + 1}: Accuracy = {fold_metrics[\"accuracy\"]}')\n",
    "\n",
    "    return all_fold_metrics\n",
    "\n",
    "# Define k-fold cross-validation settings\n",
    "kf_5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "kf_15 = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "kf_20 = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through different numbers of folds\n",
    "kfolds = [kf_20]# kf_10, kf_15, kf_20\n",
    "\n",
    "\n",
    "for num_folds, kf in zip([20], kfolds):\n",
    "    print(f'Number of Folds: {num_folds}')\n",
    "\n",
    "    # Perform cross-validation for each fold\n",
    "    fold_metrics = voting_cross_validation(X, y, num_folds)\n",
    "\n",
    "    # Calculate and print mean of metrics for all folds\n",
    "    mean_metrics = {metric: np.mean([fold[metric] for fold in fold_metrics]) for metric in fold_metrics[0]}\n",
    "    mean_metrics['k_value'] = num_folds\n",
    "    # Append mean metrics to the DataFrame\n",
    "    mean_metrics_df = mean_metrics_df.append(mean_metrics, ignore_index=True)\n",
    "\n",
    "    # Print mean metrics for all folds\n",
    "    print('Mean Metrics for All Folds:')\n",
    "    for metric, value in mean_metrics.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "# Save mean metrics to a CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc2bc8",
   "metadata": {},
   "source": [
    "Metrics for k=5,10,15,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "939e6c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>k_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860773</td>\n",
       "      <td>0.737513</td>\n",
       "      <td>0.499368</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.878334</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.860990</td>\n",
       "      <td>0.737295</td>\n",
       "      <td>0.501322</td>\n",
       "      <td>0.596764</td>\n",
       "      <td>0.879519</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.861770</td>\n",
       "      <td>0.740837</td>\n",
       "      <td>0.501898</td>\n",
       "      <td>0.598340</td>\n",
       "      <td>0.879807</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861098</td>\n",
       "      <td>0.737761</td>\n",
       "      <td>0.501169</td>\n",
       "      <td>0.596775</td>\n",
       "      <td>0.879593</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1   roc_auc  k_value\n",
       "0  0.860773   0.737513  0.499368  0.595500  0.878334      5.0\n",
       "1  0.860990   0.737295  0.501322  0.596764  0.879519     10.0\n",
       "2  0.861770   0.740837  0.501898  0.598340  0.879807     15.0\n",
       "3  0.861098   0.737761  0.501169  0.596775  0.879593     20.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f20555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
